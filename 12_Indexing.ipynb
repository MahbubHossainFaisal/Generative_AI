{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b593a45b",
   "metadata": {},
   "source": [
    "### Topic: Indexing in Vector Stores\n",
    "\n",
    "Indexing is an advanced technique used to efficiently manage and search through large datasets in a **Vector Store**. It allows us to organize embeddings (numerical representations of text, images, etc.) in a way that makes retrieval faster and more accurate. Let’s dive into why indexing is needed, its benefits, and how it works.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Why is Indexing Needed?**\n",
    "\n",
    "### **Problem: Searching Large Datasets is Slow**\n",
    "- Without indexing, searching through a large dataset (e.g., millions of embeddings) would require comparing the query embedding with every single embedding in the dataset.\n",
    "- This is computationally expensive and slow, especially for real-time applications.\n",
    "\n",
    "### **Solution: Indexing**\n",
    "- Indexing organizes embeddings in a way that allows for **fast and efficient retrieval**.\n",
    "- Instead of comparing the query embedding with every embedding in the dataset, indexing reduces the search space by grouping similar embeddings together.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Benefits of Indexing**\n",
    "\n",
    "1. **Faster Retrieval**:\n",
    "   - Indexing enables **sublinear search times**, meaning the search time grows slower than the size of the dataset.\n",
    "\n",
    "2. **Scalability**:\n",
    "   - Indexing allows Vector Stores to handle **millions or even billions of embeddings** efficiently.\n",
    "\n",
    "3. **Improved Accuracy**:\n",
    "   - Advanced indexing techniques (e.g., **Hierarchical Navigable Small World (HNSW)** ensure that the most relevant embeddings are retrieved.\n",
    "\n",
    "4. **Resource Efficiency**:\n",
    "   - Indexing reduces the computational resources required for searching, making it feasible to run on standard hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. How Does Indexing Work?**\n",
    "\n",
    "Indexing works by organizing embeddings into a structured format that allows for efficient search. Here’s a step-by-step explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Generate Embeddings**\n",
    "- Convert text, images, or other data into numerical vectors (embeddings) using an **embedding model** (e.g., OpenAI's `text-embedding-ada-002`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Build the Index**\n",
    "- Use an **indexing algorithm** (e.g., HNSW, FAISS) to organize the embeddings into a searchable structure.\n",
    "- The index groups similar embeddings together, making it easier to find the most relevant ones for a given query.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Perform Similarity Search**\n",
    "- When a user queries the system, convert the query into an embedding.\n",
    "- Use the index to quickly find the **k most relevant embeddings** (e.g., using **Top-k retrieval**).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Retrieve and Use Information**\n",
    "- The retrieved embeddings (and their associated text or data) are fed into an LLM or other system to generate a response.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example: Indexing with FAISS**\n",
    "\n",
    "Let’s say you have a large dataset of text documents, and you want to build an index for efficient retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Generate Embeddings**\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Generate embeddings for the text\n",
    "texts = [\n",
    "    \"Generative AI is a type of artificial intelligence that can create new content.\",\n",
    "    \"It works by learning patterns from existing data and using those patterns to generate new, similar data.\",\n",
    "    \"Large Language Models (LLMs) like GPT-4 are examples of generative AI models.\"\n",
    "]\n",
    "embedding_list = [embeddings.embed_query(text) for text in texts]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Build the Index**\n",
    "```python\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embedding_array = np.array(embedding_list).astype('float32')\n",
    "\n",
    "# Build the FAISS index\n",
    "dimension = embedding_array.shape[1]  # Dimension of the embeddings\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity search\n",
    "index.add(embedding_array)  # Add embeddings to the index\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Perform Similarity Search**\n",
    "```python\n",
    "# Convert the query into an embedding\n",
    "query = \"What is generative AI?\"\n",
    "query_embedding = np.array([embeddings.embed_query(query)]).astype('float32')\n",
    "\n",
    "# Perform Top-k retrieval (k=2)\n",
    "k = 2\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Retrieve the most relevant texts\n",
    "results = [texts[i] for i in indices[0]]\n",
    "print(results)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "```\n",
    "[\n",
    "    \"Generative AI is a type of artificial intelligence that can create new content.\",\n",
    "    \"Large Language Models (LLMs) like GPT-4 are examples of generative AI models.\"\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Benefits of Indexing**\n",
    "\n",
    "1. **Faster Retrieval**:\n",
    "   - Indexing reduces search times by organizing embeddings into a structured format.\n",
    "\n",
    "2. **Scalability**:\n",
    "   - Indexing allows Vector Stores to handle large datasets efficiently.\n",
    "\n",
    "3. **Improved Accuracy**:\n",
    "   - Advanced indexing techniques ensure that the most relevant embeddings are retrieved.\n",
    "\n",
    "4. **Resource Efficiency**:\n",
    "   - Indexing reduces the computational resources required for searching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5a74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
