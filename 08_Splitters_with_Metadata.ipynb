{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199c8399",
   "metadata": {},
   "source": [
    "### Topic: Splitters with Metadata\n",
    "\n",
    "When working with large documents, splitting text into smaller chunks is essential for processing by Large Language Models (LLMs). However, simply splitting text into chunks isn’t always enough. Sometimes, we need to **preserve additional information** about the chunks, such as where they came from (e.g., page number, section title, or source document). This is where **Splitters with Metadata** come into play.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Why is Metadata Needed?**\n",
    "\n",
    "### **Problem: Loss of Context**\n",
    "- When you split a document into chunks, the LLM loses information about the **origin** of each chunk.\n",
    "- For example:\n",
    "  - If a chunk comes from a specific section of a document (e.g., \"Introduction\" or \"Conclusion\"), the LLM won’t know this unless you explicitly tell it.\n",
    "  - If a chunk comes from a specific page in a PDF, the LLM won’t know which page it’s from.\n",
    "\n",
    "### **Solution: Metadata**\n",
    "- **Metadata** is additional information attached to each chunk.\n",
    "- It helps the LLM understand the **context** of the chunk, such as:\n",
    "  - The source document.\n",
    "  - The page number.\n",
    "  - The section title.\n",
    "  - The author or timestamp.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Benefits of Splitters with Metadata**\n",
    "\n",
    "1. **Preserves Context**:\n",
    "   - Metadata helps the LLM understand where each chunk came from, improving the accuracy of responses.\n",
    "\n",
    "2. **Enables Better Retrieval**:\n",
    "   - When using techniques like **Retrieval-Augmented Generation (RAG)**, metadata helps retrieve the most relevant chunks.\n",
    "\n",
    "3. **Improves Traceability**:\n",
    "   - You can trace back each chunk to its original source, which is useful for debugging or auditing.\n",
    "\n",
    "4. **Supports Complex Workflows**:\n",
    "   - Metadata allows you to build more advanced workflows, such as filtering chunks based on specific criteria (e.g., only use chunks from the \"Introduction\" section).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. What Problem Does It Solve?**\n",
    "\n",
    "### **Scenario: Building a Document-Based Q&A System**\n",
    "Imagine you’re building a Q&A system that answers questions based on a large document (e.g., a 100-page PDF). Here’s how metadata solves key problems:\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem 1: Loss of Source Information**\n",
    "- Without metadata, the LLM won’t know which page or section a chunk came from.\n",
    "- For example:\n",
    "  - If a user asks, *\"What does the Introduction say about AI?\"*, the system won’t know which chunks belong to the \"Introduction\" section.\n",
    "\n",
    "### **Solution: Add Metadata**\n",
    "- Attach metadata to each chunk, such as:\n",
    "  - `section: \"Introduction\"`\n",
    "  - `page: 5`\n",
    "- Now, when the user asks about the \"Introduction,\" the system can filter chunks based on the `section` metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem 2: Inefficient Retrieval**\n",
    "- Without metadata, the system might retrieve irrelevant chunks.\n",
    "- For example:\n",
    "  - If a user asks, *\"What is the conclusion?\"*, the system might retrieve chunks from the middle of the document instead of the \"Conclusion\" section.\n",
    "\n",
    "### **Solution: Use Metadata for Filtering**\n",
    "- Attach metadata like `section: \"Conclusion\"` to relevant chunks.\n",
    "- During retrieval, filter chunks based on the `section` metadata to ensure only relevant chunks are used.\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem 3: Lack of Traceability**\n",
    "- Without metadata, you can’t trace back a chunk to its original source.\n",
    "- For example:\n",
    "  - If the LLM generates an incorrect response, you won’t know which part of the document caused the error.\n",
    "\n",
    "### **Solution: Include Source Information in Metadata**\n",
    "- Attach metadata like `source: \"document.pdf\"` and `page: 10` to each chunk.\n",
    "- Now, you can trace back each chunk to its original source for debugging or verification.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example Scenario: Splitting a PDF with Metadata**\n",
    "\n",
    "Let’s say you have a PDF document with the following structure:\n",
    "- **Title Page**: Page 1\n",
    "- **Introduction**: Pages 2–5\n",
    "- **Main Content**: Pages 6–50\n",
    "- **Conclusion**: Pages 51–52\n",
    "\n",
    "You want to split this PDF into chunks and attach metadata to each chunk.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Split the Document**\n",
    "Use a text splitter to divide the document into smaller chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Attach Metadata**\n",
    "For each chunk, attach metadata like:\n",
    "- `source`: The name of the document (e.g., `\"document.pdf\"`).\n",
    "- `page`: The page number the chunk came from.\n",
    "- `section`: The section the chunk belongs to (e.g., `\"Introduction\"`, `\"Conclusion\"`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Splitting with Metadata**\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Sample text with metadata\n",
    "text = \"\"\"\n",
    "Introduction\n",
    "Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music. \n",
    "It works by learning patterns from existing data and using those patterns to generate new, similar data.\n",
    "\n",
    "Main Content\n",
    "Large Language Models (LLMs) like GPT-4 are examples of generative AI models. They are trained on vast amounts of text data and can generate human-like text.\n",
    "\n",
    "Conclusion\n",
    "In conclusion, generative AI has the potential to revolutionize many industries, from healthcare to entertainment.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the splitter\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=100,  # Each chunk will have up to 100 characters\n",
    "    chunk_overlap=20  # Overlap of 20 characters between chunks\n",
    ")\n",
    "\n",
    "# Split the text\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Attach metadata to each chunk\n",
    "metadata = [\n",
    "    {\"source\": \"document.pdf\", \"page\": 2, \"section\": \"Introduction\"},\n",
    "    {\"source\": \"document.pdf\", \"page\": 6, \"section\": \"Main Content\"},\n",
    "    {\"source\": \"document.pdf\", \"page\": 51, \"section\": \"Conclusion\"}\n",
    "]\n",
    "\n",
    "# Combine chunks with metadata\n",
    "chunks_with_metadata = [\n",
    "    {\"text\": chunk, \"metadata\": metadata[i]} \n",
    "    for i, chunk in enumerate(chunks)\n",
    "]\n",
    "\n",
    "# Print the chunks with metadata\n",
    "for chunk in chunks_with_metadata:\n",
    "    print(f\"Text: {chunk['text']}\")\n",
    "    print(f\"Metadata: {chunk['metadata']}\\n\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "```\n",
    "Text: Introduction\n",
    "Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music.\n",
    "Metadata: {'source': 'document.pdf', 'page': 2, 'section': 'Introduction'}\n",
    "\n",
    "Text: It works by learning patterns from existing data and using those patterns to generate new, similar data.\n",
    "Metadata: {'source': 'document.pdf', 'page': 2, 'section': 'Introduction'}\n",
    "\n",
    "Text: Main Content\n",
    "Large Language Models (LLMs) like GPT-4 are examples of generative AI models. They are trained on vast amounts of text data and can generate human-like text.\n",
    "Metadata: {'source': 'document.pdf', 'page': 6, 'section': 'Main Content'}\n",
    "\n",
    "Text: Conclusion\n",
    "In conclusion, generative AI has the potential to revolutionize many industries, from healthcare to entertainment.\n",
    "Metadata: {'source': 'document.pdf', 'page': 51, 'section': 'Conclusion'}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Benefits of Splitters with Metadata**\n",
    "\n",
    "1. **Context Preservation**:\n",
    "   - Metadata helps the LLM understand the context of each chunk, improving response accuracy.\n",
    "\n",
    "2. **Efficient Retrieval**:\n",
    "   - Metadata allows you to filter and retrieve only the most relevant chunks.\n",
    "\n",
    "3. **Traceability**:\n",
    "   - You can trace back each chunk to its original source for debugging or auditing.\n",
    "\n",
    "4. **Advanced Workflows**:\n",
    "   - Metadata enables complex workflows, such as filtering chunks based on specific criteria (e.g., only use chunks from the \"Conclusion\" section).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20267061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
