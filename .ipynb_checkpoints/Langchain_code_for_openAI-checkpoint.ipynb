{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0bfea9f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Step 1: Setting Up Your Environment**\n",
    "\n",
    "#### **1.1 Create a Folder**\n",
    "First, create a dedicated folder for your project. This will help you keep everything organized.\n",
    "\n",
    "```bash\n",
    "mkdir gen-ai-project\n",
    "cd gen-ai-project\n",
    "```\n",
    "\n",
    "#### **1.2 Create a Virtual Environment**\n",
    "A virtual environment is crucial for managing dependencies and ensuring that your project runs smoothly without conflicts.\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "```\n",
    "\n",
    "- **Explanation**: This command creates a virtual environment named `venv` in your project directory.\n",
    "\n",
    "#### **1.3 Activate the Virtual Environment**\n",
    "Activate the virtual environment to isolate your project’s dependencies.\n",
    "\n",
    "- **On macOS/Linux**:\n",
    "  ```bash\n",
    "  source venv/bin/activate\n",
    "  ```\n",
    "- **On Windows**:\n",
    "  ```bash\n",
    "  venv\\Scripts\\activate\n",
    "  ```\n",
    "\n",
    "- **Explanation**: Activating the virtual environment ensures that any packages you install are specific to this project.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Installing Required Libraries**\n",
    "\n",
    "#### **2.1 Create a `requirements.txt` File**\n",
    "This file will list all the necessary libraries for your project.\n",
    "\n",
    "```bash\n",
    "touch requirements.txt\n",
    "```\n",
    "\n",
    "Open the `requirements.txt` file and add the following libraries:\n",
    "\n",
    "```plaintext\n",
    "# LangChain Core\n",
    "langchain\n",
    "langchain-core\n",
    "\n",
    "# OpenAI Integration\n",
    "langchain-openai\n",
    "openai\n",
    "\n",
    "# Anthropic Integration\n",
    "langchain-anthropic\n",
    "\n",
    "# Google Gemini (PaLM) Integration\n",
    "langchain-google-genai\n",
    "google-generativeai\n",
    "\n",
    "# Hugging Face Integration\n",
    "langchain-huggingface\n",
    "transformers\n",
    "huggingface-hub\n",
    "\n",
    "# Environment Variable Management\n",
    "python-dotenv\n",
    "\n",
    "# Machine Learning Utilities\n",
    "numpy\n",
    "scikit-learn\n",
    "```\n",
    "\n",
    "- **Explanation**: These libraries are essential for integrating LangChain with various AI platforms like OpenAI, Anthropic, Google Gemini, and Hugging Face.\n",
    "\n",
    "#### **2.2 Install the Packages**\n",
    "Install the libraries listed in `requirements.txt` using pip.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "- **Explanation**: This command installs all the required packages in your virtual environment.\n",
    "\n",
    "#### **2.3 Test the Installation**\n",
    "Verify that LangChain is installed correctly by checking its version.\n",
    "\n",
    "```python\n",
    "python -c \"import langchain; print(langchain.__version__)\"\n",
    "```\n",
    "\n",
    "- **Explanation**: This command imports LangChain and prints its version, confirming that the installation was successful.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Organizing Your Project**\n",
    "\n",
    "#### **3.1 Create Folders for Different Model Types**\n",
    "Create three folders to organize your code based on the type of models you’ll be working with.\n",
    "\n",
    "```bash\n",
    "mkdir LLMs ChatModels EmbeddedModels\n",
    "```\n",
    "\n",
    "- **Explanation**:\n",
    "  - **LLMs**: For Language Models that take a string as input and return a string as output.\n",
    "  - **ChatModels**: For models designed for conversational AI.\n",
    "  - **EmbeddedModels**: For models that generate embeddings (vector representations of text).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Working with LLMs (Language Models)**\n",
    "\n",
    "#### **4.1 Obtain OpenAI API Keys**\n",
    "To interact with OpenAI’s models, you’ll need an API key.\n",
    "\n",
    "1. Go to [platform.openai.com](https://platform.openai.com) and create an account.\n",
    "2. Add a payment method to access credits (minimum $5).\n",
    "3. Navigate to **API Keys** and create a new secret key.\n",
    "\n",
    "#### **4.2 Store the API Key in a `.env` File**\n",
    "Create a `.env` file in your project directory to securely store your API key.\n",
    "\n",
    "```bash\n",
    "touch .env\n",
    "```\n",
    "\n",
    "Add the following line to the `.env` file:\n",
    "\n",
    "```plaintext\n",
    "OPENAI_API_KEY=\"<your_secret_key>\"\n",
    "```\n",
    "\n",
    "- **Explanation**: The `.env` file is used to store environment variables, keeping sensitive information like API keys secure.\n",
    "\n",
    "#### **4.3 Create a Python Script for LLMs**\n",
    "Under the `LLMs` folder, create a file named `llm_demo.py`.\n",
    "\n",
    "```bash\n",
    "touch LLMs/llm_demo.py\n",
    "```\n",
    "\n",
    "#### **4.4 Write the Code**\n",
    "Open `llm_demo.py` and add the following code:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"Explain the concept of quantum computing in simple terms.\"\n",
    "\n",
    "# Invoke the model with the prompt\n",
    "result = llm.invoke(prompt)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n",
    "```\n",
    "\n",
    "- **Explanation**:\n",
    "  - **`load_dotenv()`**: Loads the API key from the `.env` file.\n",
    "  - **`OpenAI()`**: Initializes the OpenAI model.\n",
    "  - **`llm.invoke(prompt)`**: Sends the prompt to the model and retrieves the response.\n",
    "\n",
    "#### **4.5 Run the Script**\n",
    "Execute the script to see the model’s response.\n",
    "\n",
    "```bash\n",
    "python LLMs/llm_demo.py\n",
    "```\n",
    "\n",
    "- **Explanation**: This command runs the script, and you should see the model’s output printed in the terminal.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Transitioning to ChatModels**\n",
    "\n",
    "#### **5.1 Why ChatModels?**\n",
    "While LLMs are powerful, ChatModels are designed specifically for conversational AI, making them more suitable for interactive applications.\n",
    "\n",
    "#### **5.2 Example: Using ChatModels**\n",
    "Create a new file under the `ChatModels` folder named `chat_demo.py`.\n",
    "\n",
    "```bash\n",
    "touch ChatModels/chat_demo.py\n",
    "```\n",
    "\n",
    "Add the following code:\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "chat_model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Define a conversation prompt\n",
    "prompt = \"Can you help me write a poem about the ocean?\"\n",
    "\n",
    "# Invoke the chat model\n",
    "response = chat_model.invoke(prompt)\n",
    "\n",
    "# Print the response\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "- **Explanation**:\n",
    "  - **`ChatOpenAI()`**: Initializes a chat-based model.\n",
    "  - **`response.content`**: Extracts the model’s response from the chat object.\n",
    "\n",
    "#### **5.3 Run the Script**\n",
    "Execute the script to see the chat model’s response.\n",
    "\n",
    "```bash\n",
    "python ChatModels/chat_demo.py\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425f89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
