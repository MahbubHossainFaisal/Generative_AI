{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4892fff8",
   "metadata": {},
   "source": [
    "### Topic: Splitters in LangChain\n",
    "\n",
    "Splitters are essential tools in LangChain for breaking down large documents into smaller, manageable chunks. This is particularly important when working with Large Language Models (LLMs) that have **context window limitations**. By splitting documents into smaller pieces, we can ensure that the LLM can process the information effectively and generate accurate responses.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Why Splitters are Needed**\n",
    "\n",
    "### **Problem: Context Window Limitation**\n",
    "- LLMs can only process a limited amount of text at once (e.g., 4k, 8k, or 32k tokens).\n",
    "- Large documents (e.g., books, research papers) cannot be processed in one go.\n",
    "\n",
    "### **Solution: Splitters**\n",
    "- Splitters divide large documents into smaller chunks that fit within the LLM's context window.\n",
    "- These chunks can then be processed individually or used in techniques like **Retrieval-Augmented Generation (RAG)**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Common Splitters in LangChain**\n",
    "\n",
    "LangChain provides a variety of splitters to handle different types of documents and splitting strategies. Here are some of the most important and commonly used splitters:\n",
    "\n",
    "1. **CharacterTextSplitter**: Splits text based on character count.\n",
    "2. **RecursiveCharacterTextSplitter**: Splits text recursively to ensure chunks are semantically meaningful.\n",
    "3. **TokenTextSplitter**: Splits text based on token count (useful for LLMs with token limits).\n",
    "4. **MarkdownHeaderTextSplitter**: Splits Markdown documents based on headers.\n",
    "\n",
    "Let’s dive deeper into **CharacterTextSplitter** and provide an example.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. CharacterTextSplitter**\n",
    "\n",
    "### **What is CharacterTextSplitter?**\n",
    "- **CharacterTextSplitter** splits text into chunks based on a specified number of characters.\n",
    "- It is useful when you want to divide text into fixed-size chunks.\n",
    "\n",
    "### **Key Parameters**:\n",
    "- `chunk_size`: The maximum number of characters in each chunk.\n",
    "- `chunk_overlap`: The number of overlapping characters between consecutive chunks (to maintain context).\n",
    "\n",
    "### **Example: Using CharacterTextSplitter**\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"\n",
    "Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music. \n",
    "It works by learning patterns from existing data and using those patterns to generate new, similar data. \n",
    "Large Language Models (LLMs) like GPT-4 are examples of generative AI models.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the splitter\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=100,  # Each chunk will have up to 100 characters\n",
    "    chunk_overlap=20  # Overlap of 20 characters between chunks\n",
    ")\n",
    "\n",
    "# Split the text\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Print the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\\n\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "```\n",
    "Chunk 1: Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music.\n",
    "\n",
    "Chunk 2: It works by learning patterns from existing data and using those patterns to generate new, similar data.\n",
    "\n",
    "Chunk 3: Large Language Models (LLMs) like GPT-4 are examples of generative AI models.\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- The text is split into chunks of **100 characters** each.\n",
    "- Each chunk overlaps with the next by **20 characters** to maintain context.\n",
    "- The resulting chunks are small enough to fit within the LLM's context window.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Other Important Splitters**\n",
    "\n",
    "### **a. RecursiveCharacterTextSplitter**\n",
    "- Splits text recursively to ensure chunks are semantically meaningful.\n",
    "- Useful for preserving the structure of the text (e.g., paragraphs, sentences).\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "chunks = splitter.split_text(text)\n",
    "```\n",
    "\n",
    "### **b. TokenTextSplitter**\n",
    "- Splits text based on token count (useful for LLMs with token limits).\n",
    "- Ensures chunks fit within the LLM's token limit.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=50,  # Each chunk will have up to 50 tokens\n",
    "    chunk_overlap=10  # Overlap of 10 tokens between chunks\n",
    ")\n",
    "chunks = splitter.split_text(text)\n",
    "```\n",
    "\n",
    "### **c. MarkdownHeaderTextSplitter**\n",
    "- Splits Markdown documents based on headers (e.g., `#`, `##`).\n",
    "- Useful for preserving the hierarchical structure of Markdown documents.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "chunks = splitter.split_text(text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Benefits of Using Splitters**\n",
    "\n",
    "1. **Efficient Processing**: Splitters ensure that large documents are broken into manageable chunks that fit within the LLM's context window.\n",
    "2. **Context Preservation**: Overlapping chunks help maintain context between consecutive chunks.\n",
    "3. **Flexibility**: LangChain provides a variety of splitters to handle different types of documents and splitting strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc893f",
   "metadata": {},
   "source": [
    "## **What is `chunk_overlap`?**\n",
    "\n",
    "When you split a large document into smaller chunks, **`chunk_overlap`** is the number of characters (or tokens) that overlap between consecutive chunks. This overlap ensures that **context is preserved** between chunks, making it easier for the LLM to understand the relationship between them.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why is `chunk_overlap` Needed?**\n",
    "\n",
    "Imagine you have a long paragraph, and you split it into two chunks without any overlap:\n",
    "\n",
    "**Original Text**:\n",
    "```\n",
    "Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music. It works by learning patterns from existing data and using those patterns to generate new, similar data.\n",
    "```\n",
    "\n",
    "**Without Overlap**:\n",
    "- **Chunk 1**: `Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music.`\n",
    "- **Chunk 2**: `It works by learning patterns from existing data and using those patterns to generate new, similar data.`\n",
    "\n",
    "Here, the second chunk starts abruptly with \"It works by...\", and the LLM might not fully understand the connection between the two chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### **With `chunk_overlap`**\n",
    "\n",
    "If you add an overlap of, say, **20 characters**, the chunks will look like this:\n",
    "\n",
    "**With Overlap**:\n",
    "- **Chunk 1**: `Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music.`\n",
    "- **Chunk 2**: `text, images, or music. It works by learning patterns from existing data and using those patterns to generate new, similar data.`\n",
    "\n",
    "Now, the second chunk starts with some text from the end of the first chunk (`text, images, or music.`), which helps the LLM understand the connection between the two chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### **How Does `chunk_overlap` Work?**\n",
    "\n",
    "Let’s break it down with an example:\n",
    "\n",
    "#### **Example**:\n",
    "```python\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"\n",
    "Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music. \n",
    "It works by learning patterns from existing data and using those patterns to generate new, similar data. \n",
    "Large Language Models (LLMs) like GPT-4 are examples of generative AI models.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the splitter\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=100,  # Each chunk will have up to 100 characters\n",
    "    chunk_overlap=20  # Overlap of 20 characters between chunks\n",
    ")\n",
    "\n",
    "# Split the text\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Print the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\\n\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "```\n",
    "Chunk 1: Generative AI is a type of artificial intelligence that can create new content, such as text, images, or music.\n",
    "\n",
    "Chunk 2: text, images, or music. It works by learning patterns from existing data and using those patterns to generate new, similar data.\n",
    "\n",
    "Chunk 3: patterns to generate new, similar data. Large Language Models (LLMs) like GPT-4 are examples of generative AI models.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of the Output**:\n",
    "1. **Chunk 1**:\n",
    "   - Contains the first 100 characters of the text.\n",
    "   - Ends with: `...text, images, or music.`\n",
    "\n",
    "2. **Chunk 2**:\n",
    "   - Starts with the last 20 characters of Chunk 1 (`text, images, or music.`).\n",
    "   - Adds the next 80 characters to make a total of 100 characters.\n",
    "   - Ends with: `...generate new, similar data.`\n",
    "\n",
    "3. **Chunk 3**:\n",
    "   - Starts with the last 20 characters of Chunk 2 (`patterns to generate new, similar data.`).\n",
    "   - Adds the remaining text.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why is `chunk_overlap` Important?**\n",
    "1. **Preserves Context**:\n",
    "   - Overlapping chunks ensure that the LLM can understand the relationship between consecutive chunks.\n",
    "   - Without overlap, the LLM might lose context when processing separate chunks.\n",
    "\n",
    "2. **Improves Accuracy**:\n",
    "   - By maintaining context, the LLM can generate more accurate and coherent responses.\n",
    "\n",
    "3. **Handles Edge Cases**:\n",
    "   - If a sentence or idea is split across two chunks, the overlap ensures that the LLM can still understand the full meaning.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `chunk_overlap`?**\n",
    "- Use `chunk_overlap` when:\n",
    "  - The text contains long sentences or ideas that span multiple chunks.\n",
    "  - You want to ensure that the LLM can maintain context between chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Diagram of `chunk_overlap`**\n",
    "\n",
    "```\n",
    "+-------------------+       +-------------------+       +-------------------+\n",
    "|    Chunk 1        | ----> |    Chunk 2        | ----> |    Chunk 3        |\n",
    "|    (100 chars)    |       |    (100 chars)    |       |    (100 chars)    |\n",
    "+-------------------+       +-------------------+       +-------------------+\n",
    "|                   |       |                   |       |                   |\n",
    "|   [Overlap: 20]   | <---->|   [Overlap: 20]   | <---->|                   |\n",
    "|                   |       |                   |       |                   |\n",
    "+-------------------+       +-------------------+       +-------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "- **`chunk_overlap`** is the number of overlapping characters (or tokens) between consecutive chunks.\n",
    "- It helps preserve context and improve the accuracy of the LLM's responses.\n",
    "- Use it when splitting large documents into smaller chunks for processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ea63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
